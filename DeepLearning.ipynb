{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hana20-ai/deep_learning_with_Colab/blob/main/DeepLearning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_RH_VIFA4bac"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "import os,datetime\n",
        "import tensorflow_datasets as tfds\n",
        "\n",
        "#import data from tensorflow_datasets \n",
        "data,info = tfds.load ( 'patch_camelyon', with_info = True, as_supervised = True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QU_MK2KMAJku"
      },
      "outputs": [],
      "source": [
        "#Récuperer les données d'entrainement, de test et de validation dans le dataset \n",
        "train_data = data['train']\n",
        "valid_data = data['validation']\n",
        "test_data = data['test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mDHbpi-T4a72"
      },
      "outputs": [],
      "source": [
        "#Normalisation des données (les images) : Prétraitement des images \n",
        "#fonction de prétraitement d'UNE image \n",
        "def pretrait(image, labels):\n",
        "  image = tf.cast(image, tf.float32)\n",
        "  #les pixels seront de format 0 et 1 en virgule flottante\n",
        "  image /= 255.0  \n",
        "  return image, labels\n",
        "\n",
        "#Appliquer le prétraitement sur les ensembles de données en utilisant la fonction map()\n",
        "train_data = train_data.map(pretrait)\n",
        "valid_data = valid_data.map(pretrait)\n",
        "test_data = test_data.map(pretrait)\n",
        "\n",
        "\n",
        "\n",
        "#normalisation par lots en utilisant la fonction prefetch \n",
        "batch_size = 128 \n",
        "train_data = train_data.batch(batch_size).prefetch(1)\n",
        "valid_data = valid_data.batch(batch_size).prefetch(1)\n",
        "test_data = test_data.batch(batch_size).prefetch(1)\n",
        "\n",
        "\n",
        "#Séparer les images et leurs étiquettes lot par lot  pour les trois sous ensembles de données (appren supervisé) \n",
        "train_images, train_labels = next(iter(train_data))\n",
        "valid_images, valid_labels = next(iter(valid_data))\n",
        "test_images, test_labels  = next(iter(test_data))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LQunwCjuRBp5"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import Sequential #le modele utilisé est séquentiel\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, BatchNormalization, Dropout #les couches CNN \n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras import regularizers \n",
        "\n",
        "#création d'un réseau de neurones avec n couches \n",
        "model = Sequential([\n",
        "                    Conv2D(256, 3,padding='same', kernel_initializer='he_uniform', activation='relu', input_shape = [96, 96, 3]),\n",
        "                    MaxPooling2D(2),\n",
        "\n",
        "                    Conv2D(256, 3,padding='same', kernel_initializer='he_uniform',activation='relu',),\n",
        "                    MaxPooling2D(2),\n",
        "\n",
        "                    Conv2D(512, 3,padding='same',kernel_initializer='he_uniform',activation='relu',),\n",
        "                    MaxPooling2D(2),\n",
        "\n",
        "                    Conv2D(512, 3,padding='same',kernel_initializer='he_uniform',activation='relu',),\n",
        "                    MaxPooling2D(2),\n",
        "\n",
        "                    Conv2D(1024, 3,padding='same', kernel_initializer='he_uniform',activation='relu',),\n",
        "                    MaxPooling2D(2),\n",
        "\n",
        "                    Conv2D(1024, 3,padding='same', kernel_initializer='he_uniform',activation='relu',),\n",
        "                    MaxPooling2D(2),\n",
        "\n",
        "                    Flatten(),\n",
        "\n",
        "                    #output layers: fully connected layers \n",
        "                    Dense(1024,kernel_initializer='he_uniform',activation = 'relu'),\n",
        "                    Dense(512,kernel_initializer='he_uniform',activation = 'relu'),\n",
        "                    Dense(256,kernel_initializer='he_uniform',activation = 'relu'),\n",
        "\n",
        "                    Dense(1, activation = 'sigmoid'),\n",
        "                    \n",
        "                    ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fkxFKEDeRqzx",
        "outputId": "ec3a1b53-7da6-4328-c6d6-817f0efdb61b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_6 (Conv2D)           (None, 96, 96, 256)       7168      \n",
            "                                                                 \n",
            " max_pooling2d_6 (MaxPooling  (None, 48, 48, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 48, 48, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_7 (MaxPooling  (None, 24, 24, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_8 (Conv2D)           (None, 24, 24, 512)       1180160   \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPooling  (None, 12, 12, 512)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 12, 12, 512)       2359808   \n",
            "                                                                 \n",
            " max_pooling2d_9 (MaxPooling  (None, 6, 6, 512)        0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 6, 6, 1024)        4719616   \n",
            "                                                                 \n",
            " max_pooling2d_10 (MaxPoolin  (None, 3, 3, 1024)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " conv2d_11 (Conv2D)          (None, 3, 3, 1024)        9438208   \n",
            "                                                                 \n",
            " max_pooling2d_11 (MaxPoolin  (None, 1, 1, 1024)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 256)               131328    \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 20,001,025\n",
            "Trainable params: 20,001,025\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fRrE6oyPvLY",
        "outputId": "fb4c2a9d-b200-467a-d007-444570fd9daa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "4/4 - 75s - loss: 3.2859 - accuracy: 0.7031 - val_loss: 3.4275 - val_accuracy: 0.4141 - 75s/epoch - 19s/step\n",
            "Epoch 2/100\n",
            "4/4 - 70s - loss: 1.3128 - accuracy: 0.6250 - val_loss: 0.8101 - val_accuracy: 0.5859 - 70s/epoch - 17s/step\n",
            "Epoch 3/100\n",
            "4/4 - 67s - loss: 0.6623 - accuracy: 0.5703 - val_loss: 0.6402 - val_accuracy: 0.5859 - 67s/epoch - 17s/step\n",
            "Epoch 4/100\n",
            "4/4 - 66s - loss: 0.5671 - accuracy: 0.7344 - val_loss: 0.6436 - val_accuracy: 0.7109 - 66s/epoch - 17s/step\n",
            "Epoch 5/100\n",
            "4/4 - 70s - loss: 0.5296 - accuracy: 0.7891 - val_loss: 0.6627 - val_accuracy: 0.6562 - 70s/epoch - 17s/step\n",
            "Epoch 6/100\n",
            "4/4 - 67s - loss: 0.4596 - accuracy: 0.8203 - val_loss: 0.6449 - val_accuracy: 0.6094 - 67s/epoch - 17s/step\n",
            "Epoch 7/100\n",
            "4/4 - 68s - loss: 0.4178 - accuracy: 0.8594 - val_loss: 0.6680 - val_accuracy: 0.7031 - 68s/epoch - 17s/step\n",
            "Epoch 8/100\n",
            "4/4 - 66s - loss: 0.3693 - accuracy: 0.8359 - val_loss: 0.6318 - val_accuracy: 0.6953 - 66s/epoch - 17s/step\n",
            "Epoch 9/100\n",
            "4/4 - 67s - loss: 0.3358 - accuracy: 0.8672 - val_loss: 0.7005 - val_accuracy: 0.6953 - 67s/epoch - 17s/step\n",
            "Epoch 10/100\n",
            "4/4 - 66s - loss: 0.2614 - accuracy: 0.8906 - val_loss: 0.6222 - val_accuracy: 0.7422 - 66s/epoch - 17s/step\n",
            "Epoch 11/100\n",
            "4/4 - 66s - loss: 0.2132 - accuracy: 0.9297 - val_loss: 0.7728 - val_accuracy: 0.7109 - 66s/epoch - 16s/step\n",
            "Epoch 12/100\n",
            "4/4 - 65s - loss: 0.1485 - accuracy: 0.9844 - val_loss: 0.6847 - val_accuracy: 0.7422 - 65s/epoch - 16s/step\n",
            "Epoch 13/100\n",
            "4/4 - 65s - loss: 0.1094 - accuracy: 0.9688 - val_loss: 0.8352 - val_accuracy: 0.7188 - 65s/epoch - 16s/step\n",
            "Epoch 14/100\n",
            "4/4 - 65s - loss: 0.0756 - accuracy: 0.9922 - val_loss: 0.9061 - val_accuracy: 0.7266 - 65s/epoch - 16s/step\n",
            "Epoch 15/100\n",
            "4/4 - 66s - loss: 0.0517 - accuracy: 1.0000 - val_loss: 0.9393 - val_accuracy: 0.7344 - 66s/epoch - 16s/step\n",
            "Epoch 16/100\n",
            "4/4 - 66s - loss: 0.0325 - accuracy: 1.0000 - val_loss: 0.9930 - val_accuracy: 0.7344 - 66s/epoch - 16s/step\n",
            "Epoch 17/100\n",
            "4/4 - 65s - loss: 0.0183 - accuracy: 1.0000 - val_loss: 1.0137 - val_accuracy: 0.7266 - 65s/epoch - 16s/step\n",
            "Epoch 18/100\n",
            "4/4 - 66s - loss: 0.0135 - accuracy: 1.0000 - val_loss: 1.0982 - val_accuracy: 0.7344 - 66s/epoch - 17s/step\n",
            "Epoch 19/100\n",
            "4/4 - 66s - loss: 0.0078 - accuracy: 1.0000 - val_loss: 1.2617 - val_accuracy: 0.7266 - 66s/epoch - 17s/step\n",
            "Epoch 20/100\n",
            "4/4 - 67s - loss: 0.0045 - accuracy: 1.0000 - val_loss: 1.2456 - val_accuracy: 0.7500 - 67s/epoch - 17s/step\n",
            "Epoch 21/100\n",
            "4/4 - 67s - loss: 0.0033 - accuracy: 1.0000 - val_loss: 1.2802 - val_accuracy: 0.7500 - 67s/epoch - 17s/step\n",
            "Epoch 22/100\n",
            "4/4 - 66s - loss: 0.0027 - accuracy: 1.0000 - val_loss: 1.3283 - val_accuracy: 0.7500 - 66s/epoch - 17s/step\n",
            "Epoch 23/100\n",
            "4/4 - 66s - loss: 0.0015 - accuracy: 1.0000 - val_loss: 1.3901 - val_accuracy: 0.7266 - 66s/epoch - 17s/step\n",
            "Epoch 24/100\n",
            "4/4 - 66s - loss: 0.0014 - accuracy: 1.0000 - val_loss: 1.4096 - val_accuracy: 0.7344 - 66s/epoch - 17s/step\n",
            "Epoch 25/100\n",
            "4/4 - 66s - loss: 0.0010 - accuracy: 1.0000 - val_loss: 1.3953 - val_accuracy: 0.7578 - 66s/epoch - 17s/step\n",
            "Epoch 26/100\n",
            "4/4 - 66s - loss: 7.8259e-04 - accuracy: 1.0000 - val_loss: 1.3957 - val_accuracy: 0.7500 - 66s/epoch - 17s/step\n",
            "Epoch 27/100\n",
            "4/4 - 66s - loss: 7.3261e-04 - accuracy: 1.0000 - val_loss: 1.4159 - val_accuracy: 0.7500 - 66s/epoch - 17s/step\n",
            "Epoch 28/100\n",
            "4/4 - 66s - loss: 6.0326e-04 - accuracy: 1.0000 - val_loss: 1.4500 - val_accuracy: 0.7656 - 66s/epoch - 16s/step\n",
            "Epoch 29/100\n",
            "4/4 - 66s - loss: 4.8655e-04 - accuracy: 1.0000 - val_loss: 1.4915 - val_accuracy: 0.7500 - 66s/epoch - 16s/step\n",
            "Epoch 30/100\n",
            "4/4 - 66s - loss: 4.4977e-04 - accuracy: 1.0000 - val_loss: 1.5246 - val_accuracy: 0.7500 - 66s/epoch - 17s/step\n",
            "Epoch 31/100\n",
            "4/4 - 66s - loss: 4.0682e-04 - accuracy: 1.0000 - val_loss: 1.5368 - val_accuracy: 0.7500 - 66s/epoch - 17s/step\n",
            "Epoch 32/100\n",
            "4/4 - 67s - loss: 3.5517e-04 - accuracy: 1.0000 - val_loss: 1.5398 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 33/100\n",
            "4/4 - 67s - loss: 3.1513e-04 - accuracy: 1.0000 - val_loss: 1.5463 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 34/100\n",
            "4/4 - 66s - loss: 2.9370e-04 - accuracy: 1.0000 - val_loss: 1.5550 - val_accuracy: 0.7656 - 66s/epoch - 16s/step\n",
            "Epoch 35/100\n",
            "4/4 - 66s - loss: 2.6798e-04 - accuracy: 1.0000 - val_loss: 1.5711 - val_accuracy: 0.7578 - 66s/epoch - 16s/step\n",
            "Epoch 36/100\n",
            "4/4 - 66s - loss: 2.4469e-04 - accuracy: 1.0000 - val_loss: 1.5900 - val_accuracy: 0.7578 - 66s/epoch - 16s/step\n",
            "Epoch 37/100\n",
            "4/4 - 66s - loss: 2.2041e-04 - accuracy: 1.0000 - val_loss: 1.6078 - val_accuracy: 0.7578 - 66s/epoch - 16s/step\n",
            "Epoch 38/100\n",
            "4/4 - 65s - loss: 2.0470e-04 - accuracy: 1.0000 - val_loss: 1.6208 - val_accuracy: 0.7578 - 65s/epoch - 16s/step\n",
            "Epoch 39/100\n",
            "4/4 - 65s - loss: 1.8855e-04 - accuracy: 1.0000 - val_loss: 1.6372 - val_accuracy: 0.7578 - 65s/epoch - 16s/step\n",
            "Epoch 40/100\n",
            "4/4 - 67s - loss: 1.7259e-04 - accuracy: 1.0000 - val_loss: 1.6498 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 41/100\n",
            "4/4 - 67s - loss: 1.5940e-04 - accuracy: 1.0000 - val_loss: 1.6622 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 42/100\n",
            "4/4 - 68s - loss: 1.4715e-04 - accuracy: 1.0000 - val_loss: 1.6746 - val_accuracy: 0.7578 - 68s/epoch - 17s/step\n",
            "Epoch 43/100\n",
            "4/4 - 67s - loss: 1.3691e-04 - accuracy: 1.0000 - val_loss: 1.6864 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 44/100\n",
            "4/4 - 67s - loss: 1.2640e-04 - accuracy: 1.0000 - val_loss: 1.7016 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 45/100\n",
            "4/4 - 67s - loss: 1.1749e-04 - accuracy: 1.0000 - val_loss: 1.7130 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 46/100\n",
            "4/4 - 67s - loss: 1.0907e-04 - accuracy: 1.0000 - val_loss: 1.7278 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 47/100\n",
            "4/4 - 66s - loss: 1.0119e-04 - accuracy: 1.0000 - val_loss: 1.7382 - val_accuracy: 0.7578 - 66s/epoch - 17s/step\n",
            "Epoch 48/100\n",
            "4/4 - 71s - loss: 9.5550e-05 - accuracy: 1.0000 - val_loss: 1.7535 - val_accuracy: 0.7578 - 71s/epoch - 18s/step\n",
            "Epoch 49/100\n",
            "4/4 - 74s - loss: 8.8019e-05 - accuracy: 1.0000 - val_loss: 1.7596 - val_accuracy: 0.7578 - 74s/epoch - 18s/step\n",
            "Epoch 50/100\n",
            "4/4 - 75s - loss: 8.2162e-05 - accuracy: 1.0000 - val_loss: 1.7709 - val_accuracy: 0.7578 - 75s/epoch - 19s/step\n",
            "Epoch 51/100\n",
            "4/4 - 76s - loss: 7.6499e-05 - accuracy: 1.0000 - val_loss: 1.7846 - val_accuracy: 0.7578 - 76s/epoch - 19s/step\n",
            "Epoch 52/100\n",
            "4/4 - 78s - loss: 7.1251e-05 - accuracy: 1.0000 - val_loss: 1.8013 - val_accuracy: 0.7578 - 78s/epoch - 20s/step\n",
            "Epoch 53/100\n",
            "4/4 - 75s - loss: 6.6668e-05 - accuracy: 1.0000 - val_loss: 1.8144 - val_accuracy: 0.7578 - 75s/epoch - 19s/step\n",
            "Epoch 54/100\n",
            "4/4 - 67s - loss: 6.2140e-05 - accuracy: 1.0000 - val_loss: 1.8241 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 55/100\n",
            "4/4 - 67s - loss: 5.8219e-05 - accuracy: 1.0000 - val_loss: 1.8357 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 56/100\n",
            "4/4 - 67s - loss: 5.4550e-05 - accuracy: 1.0000 - val_loss: 1.8476 - val_accuracy: 0.7578 - 67s/epoch - 17s/step\n",
            "Epoch 57/100\n",
            "4/4 - 66s - loss: 5.0943e-05 - accuracy: 1.0000 - val_loss: 1.8593 - val_accuracy: 0.7578 - 66s/epoch - 16s/step\n",
            "Epoch 58/100\n",
            "4/4 - 65s - loss: 4.7799e-05 - accuracy: 1.0000 - val_loss: 1.8710 - val_accuracy: 0.7578 - 65s/epoch - 16s/step\n",
            "Epoch 59/100\n",
            "4/4 - 66s - loss: 4.4900e-05 - accuracy: 1.0000 - val_loss: 1.8861 - val_accuracy: 0.7578 - 66s/epoch - 16s/step\n",
            "Epoch 60/100\n",
            "4/4 - 65s - loss: 4.2168e-05 - accuracy: 1.0000 - val_loss: 1.8986 - val_accuracy: 0.7578 - 65s/epoch - 16s/step\n",
            "Epoch 61/100\n",
            "4/4 - 65s - loss: 3.9144e-05 - accuracy: 1.0000 - val_loss: 1.9135 - val_accuracy: 0.7500 - 65s/epoch - 16s/step\n",
            "Epoch 62/100\n",
            "4/4 - 65s - loss: 3.6935e-05 - accuracy: 1.0000 - val_loss: 1.9274 - val_accuracy: 0.7500 - 65s/epoch - 16s/step\n",
            "Epoch 63/100\n",
            "4/4 - 65s - loss: 3.4787e-05 - accuracy: 1.0000 - val_loss: 1.9370 - val_accuracy: 0.7500 - 65s/epoch - 16s/step\n",
            "Epoch 64/100\n",
            "4/4 - 65s - loss: 3.2830e-05 - accuracy: 1.0000 - val_loss: 1.9453 - val_accuracy: 0.7578 - 65s/epoch - 16s/step\n",
            "Epoch 65/100\n",
            "4/4 - 65s - loss: 3.0977e-05 - accuracy: 1.0000 - val_loss: 1.9557 - val_accuracy: 0.7578 - 65s/epoch - 16s/step\n",
            "Epoch 66/100\n",
            "4/4 - 65s - loss: 2.9065e-05 - accuracy: 1.0000 - val_loss: 1.9668 - val_accuracy: 0.7578 - 65s/epoch - 16s/step\n",
            "Epoch 67/100\n",
            "4/4 - 65s - loss: 2.7513e-05 - accuracy: 1.0000 - val_loss: 1.9800 - val_accuracy: 0.7500 - 65s/epoch - 16s/step\n",
            "Epoch 68/100\n",
            "4/4 - 60s - loss: 2.6011e-05 - accuracy: 1.0000 - val_loss: 1.9916 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 69/100\n",
            "4/4 - 60s - loss: 2.4630e-05 - accuracy: 1.0000 - val_loss: 2.0032 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 70/100\n",
            "4/4 - 60s - loss: 2.3338e-05 - accuracy: 1.0000 - val_loss: 2.0140 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 71/100\n",
            "4/4 - 60s - loss: 2.2232e-05 - accuracy: 1.0000 - val_loss: 2.0190 - val_accuracy: 0.7578 - 60s/epoch - 15s/step\n",
            "Epoch 72/100\n",
            "4/4 - 60s - loss: 2.0971e-05 - accuracy: 1.0000 - val_loss: 2.0292 - val_accuracy: 0.7578 - 60s/epoch - 15s/step\n",
            "Epoch 73/100\n",
            "4/4 - 60s - loss: 1.9938e-05 - accuracy: 1.0000 - val_loss: 2.0403 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 74/100\n",
            "4/4 - 60s - loss: 1.8918e-05 - accuracy: 1.0000 - val_loss: 2.0499 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 75/100\n",
            "4/4 - 60s - loss: 1.8050e-05 - accuracy: 1.0000 - val_loss: 2.0614 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 76/100\n",
            "4/4 - 60s - loss: 1.7170e-05 - accuracy: 1.0000 - val_loss: 2.0723 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 77/100\n",
            "4/4 - 60s - loss: 1.6325e-05 - accuracy: 1.0000 - val_loss: 2.0770 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 78/100\n",
            "4/4 - 60s - loss: 1.5504e-05 - accuracy: 1.0000 - val_loss: 2.0833 - val_accuracy: 0.7578 - 60s/epoch - 15s/step\n",
            "Epoch 79/100\n",
            "4/4 - 60s - loss: 1.4742e-05 - accuracy: 1.0000 - val_loss: 2.0941 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 80/100\n",
            "4/4 - 60s - loss: 1.4126e-05 - accuracy: 1.0000 - val_loss: 2.1025 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 81/100\n",
            "4/4 - 60s - loss: 1.3532e-05 - accuracy: 1.0000 - val_loss: 2.1141 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 82/100\n",
            "4/4 - 60s - loss: 1.2851e-05 - accuracy: 1.0000 - val_loss: 2.1232 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 83/100\n",
            "4/4 - 60s - loss: 1.2241e-05 - accuracy: 1.0000 - val_loss: 2.1297 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 84/100\n",
            "4/4 - 60s - loss: 1.1695e-05 - accuracy: 1.0000 - val_loss: 2.1388 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 85/100\n",
            "4/4 - 60s - loss: 1.1207e-05 - accuracy: 1.0000 - val_loss: 2.1470 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 86/100\n",
            "4/4 - 60s - loss: 1.0716e-05 - accuracy: 1.0000 - val_loss: 2.1553 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 87/100\n",
            "4/4 - 60s - loss: 1.0287e-05 - accuracy: 1.0000 - val_loss: 2.1652 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 88/100\n",
            "4/4 - 60s - loss: 9.8249e-06 - accuracy: 1.0000 - val_loss: 2.1727 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n",
            "Epoch 89/100\n",
            "4/4 - 60s - loss: 9.4352e-06 - accuracy: 1.0000 - val_loss: 2.1808 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 90/100\n",
            "4/4 - 60s - loss: 9.0365e-06 - accuracy: 1.0000 - val_loss: 2.1860 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 91/100\n",
            "4/4 - 60s - loss: 8.6764e-06 - accuracy: 1.0000 - val_loss: 2.1954 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 92/100\n",
            "4/4 - 60s - loss: 8.3127e-06 - accuracy: 1.0000 - val_loss: 2.2037 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 93/100\n",
            "4/4 - 65s - loss: 7.9774e-06 - accuracy: 1.0000 - val_loss: 2.2137 - val_accuracy: 0.7422 - 65s/epoch - 16s/step\n",
            "Epoch 94/100\n",
            "4/4 - 65s - loss: 7.6369e-06 - accuracy: 1.0000 - val_loss: 2.2210 - val_accuracy: 0.7422 - 65s/epoch - 16s/step\n",
            "Epoch 95/100\n",
            "4/4 - 66s - loss: 7.3436e-06 - accuracy: 1.0000 - val_loss: 2.2310 - val_accuracy: 0.7422 - 66s/epoch - 16s/step\n",
            "Epoch 96/100\n",
            "4/4 - 65s - loss: 7.0660e-06 - accuracy: 1.0000 - val_loss: 2.2373 - val_accuracy: 0.7422 - 65s/epoch - 16s/step\n",
            "Epoch 97/100\n",
            "4/4 - 65s - loss: 6.8010e-06 - accuracy: 1.0000 - val_loss: 2.2448 - val_accuracy: 0.7422 - 65s/epoch - 16s/step\n",
            "Epoch 98/100\n",
            "4/4 - 60s - loss: 6.5343e-06 - accuracy: 1.0000 - val_loss: 2.2493 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 99/100\n",
            "4/4 - 60s - loss: 6.2844e-06 - accuracy: 1.0000 - val_loss: 2.2556 - val_accuracy: 0.7500 - 60s/epoch - 15s/step\n",
            "Epoch 100/100\n",
            "4/4 - 60s - loss: 6.0961e-06 - accuracy: 1.0000 - val_loss: 2.2663 - val_accuracy: 0.7422 - 60s/epoch - 15s/step\n"
          ]
        }
      ],
      "source": [
        "#Compiler le modèle:\n",
        "\n",
        "model.compile (loss='binary_crossentropy',      #entropie binaire car les labels sont des (0,1)\n",
        "               optimizer=optimizers.Adam(1e-4), #la descente de gradient\n",
        "               metrics=['accuracy'])            #evaluer selon le taux de bonne prédiction \n",
        "\n",
        "#commencer l'appretissage\n",
        "#epochs: nb passages sur l’ensemble des exemples de la base d’apprentissage lors de la descente de gradient\n",
        "Appren = model.fit( train_images, train_labels, epochs = 100, validation_data = (valid_images, valid_labels), verbose=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y0GPNBBXgXV1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "43734e17-d03a-4a8a-87b4-c3a2565ea6a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 12s 3s/step - loss: 1.4400 - accuracy: 0.7969\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.440037488937378, 0.796875]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "#Tester le modèle \n",
        "eval= model.evaluate(test_images, test_labels)\n",
        "eval"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMkCsfRa56b876mLt9Y/T1+",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}